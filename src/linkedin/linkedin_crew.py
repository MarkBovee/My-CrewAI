from crewai import Agent, Crew, Process, Task
from crewai.project import CrewBase, agent, crew, task, before_kickoff, after_kickoff
from crewai.agents.agent_builder.base_agent import BaseAgent
from .tools.search_tool import search_tool
from .helpers.ollama_helper import LLMHelper
from .helpers.knowledge_helper import KnowledgeHelper, check_topic_similarity, store_article_completion
from typing import List

@CrewBase
class LinkedInCrew():
    """LinkedIn Content Creation Crew
    
    A multi-agent crew designed to research trending skills and create engaging 
    LinkedIn content following CrewAI best practices.
    """

    agents: List[BaseAgent]
    tasks: List[Task]

    # Configuration paths following CrewAI documentation patterns
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    def __init__(self):
        super().__init__()
        self.llm_helper = LLMHelper()
        self.knowledge_helper = KnowledgeHelper()

    @before_kickoff
    def prepare_inputs(self, inputs):
        """Prepare and validate inputs before crew execution"""
        # Add current year if not provided
        if 'current_year' not in inputs:
            import datetime
            inputs['current_year'] = datetime.datetime.now().year
        
        # Check if topic has been covered before
        topic = inputs.get('topic', 'general tech topic')
        coverage_check = check_topic_similarity(topic)
        
        print(f"üöÄ Starting LinkedIn crew with inputs: {inputs}")
        print(f"üìö Topic coverage check: {coverage_check['recommendation']}")
        
        if coverage_check['covered'] and coverage_check['similar_articles']:
            print("‚ö†Ô∏è Similar topics found:")
            for article in coverage_check['similar_articles']:
                print(f"  - {article['topic']} (similarity: {article['similarity']})")
        
        return inputs

    @after_kickoff
    def process_output(self, result):
        """Process the crew output and save content to files"""
        import os
        from datetime import datetime
        
        try:
            print("\n" + "=" * 60)
            print("üìÑ PROCESSING CREW OUTPUT AND SAVING FILES")
            print("=" * 60)
            
            # Access individual task outputs from the crew result
            # The crew result contains all task outputs in execution order
            if hasattr(result, 'tasks_output') and result.tasks_output:
                tasks_output = result.tasks_output
                print(f"‚úÖ Found {len(tasks_output)} task outputs")
                
                # Create output directories
                os.makedirs("output/articles", exist_ok=True)
                os.makedirs("output/blogs", exist_ok=True)
                os.makedirs("output/posts", exist_ok=True)
                
                # Generate timestamp and safe topic name
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                
                # Try to extract topic from the crew inputs or use a default
                topic = "Generated_Content"
                if hasattr(result, 'inputs') and 'topic' in result.inputs:
                    topic = result.inputs['topic']
                elif len(tasks_output) > 0 and hasattr(tasks_output[0], 'inputs'):
                    topic = tasks_output[0].inputs.get('topic', 'Generated_Content')
                
                topic_safe = topic.replace(" ", "_").replace("/", "_")
                
                # Task order: task_search, task_research, task_blog, task_post
                # We want to save: research (task_research), blog (task_blog), linkedin (task_post)
                
                saved_files = []
                
                # Save Research Article (task_research output - index 1)
                if len(tasks_output) > 1:
                    research_content = tasks_output[1].raw if hasattr(tasks_output[1], 'raw') else str(tasks_output[1])
                    research_file = f"output/articles/research_article_{topic_safe}_{timestamp}.md"
                    
                    research_full = f"""# Research Article: {topic}

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Topic:** {topic}  
**Type:** Comprehensive Research Article

---

{research_content}

---

*Generated by CrewAI Research Agent - Comprehensive Analysis*
"""
                    
                    with open(research_file, 'w', encoding='utf-8') as f:
                        f.write(research_full)
                    
                    saved_files.append(f"üìä Research Article: {research_file}")
                    print(f"‚úÖ Research article saved: {research_file}")
                
                # Save Blog Post (task_blog output - index 2)
                if len(tasks_output) > 2:
                    blog_content = tasks_output[2].raw if hasattr(tasks_output[2], 'raw') else str(tasks_output[2])
                    blog_file = f"output/blogs/blog_post_{topic_safe}_{timestamp}.md"
                    
                    blog_full = f"""# Blog Post: {topic}

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Topic:** {topic}  
**Type:** Experience-Driven Blog Post

---

{blog_content}

---

*Generated by CrewAI Writer Agent - Developer Experience Storytelling*
"""
                    
                    with open(blog_file, 'w', encoding='utf-8') as f:
                        f.write(blog_full)
                    
                    saved_files.append(f"üìù Blog Post: {blog_file}")
                    print(f"‚úÖ Blog post saved: {blog_file}")
                
                # Save LinkedIn Post (task_post output - index 3)
                if len(tasks_output) > 3:
                    linkedin_content = tasks_output[3].raw if hasattr(tasks_output[3], 'raw') else str(tasks_output[3])
                    linkedin_file = f"output/posts/linkedin_post_{topic_safe}_{timestamp}.md"
                    
                    linkedin_full = f"""# LinkedIn Post: {topic}

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Topic:** {topic}  
**Type:** LinkedIn Social Media Post

---

{linkedin_content}

---

*Generated by CrewAI LinkedIn Content Creation Flow*
"""
                    
                    with open(linkedin_file, 'w', encoding='utf-8') as f:
                        f.write(linkedin_full)
                    
                    saved_files.append(f"üì± LinkedIn Post: {linkedin_file}")
                    print(f"‚úÖ LinkedIn post saved: {linkedin_file}")
                
                # Summary
                if saved_files:
                    print(f"\nüéâ Successfully saved {len(saved_files)} files:")
                    for file_info in saved_files:
                        print(f"   {file_info}")
                else:
                    print("‚ö†Ô∏è  No files were saved - task outputs may be empty")
                    
            else:
                print("‚ö†Ô∏è  No task outputs found in crew result")
                print("Result type:", type(result))
                print("Result attributes:", dir(result))
                
        except Exception as e:
            print(f"‚ùå Error in process_output: {str(e)}")
            import traceback
            traceback.print_exc()
        
        # Final cleanup
        try:
            print("üßπ Cleaning up models...")
            cleanup_success = self.llm_helper.force_cleanup_memory()
            if cleanup_success:
                print("‚úÖ Model cleanup completed successfully!")
            else:
                print("‚ö†Ô∏è Model cleanup partially successful")
        except Exception as cleanup_e:
            print(f"‚ö†Ô∏è Warning: Could not complete model cleanup: {cleanup_e}")
        
        return result

    @agent
    def coach(self) -> Agent:
        """Senior Career Coach agent with search capabilities"""
        return Agent(
            config=self.agents_config['coach'], # type: ignore[index]
            llm=self.llm_helper.create_llm_instance('coach'),
            tools=[search_tool],  # Use the tool directly, not call it
            verbose=self.agents_config['coach'].get('verbose', False)
        )

    @agent
    def influencer(self) -> Agent:
        """LinkedIn Influencer Writer agent for content creation"""
        return Agent(
            config=self.agents_config['influencer'], # type: ignore[index]
            llm=self.llm_helper.create_llm_instance('influencer'),
            verbose=self.agents_config['influencer'].get('verbose', False)
        )

    @agent
    def researcher(self) -> Agent:
        """Content Researcher agent for in-depth article research"""
        return Agent(
            config=self.agents_config['researcher'], # type: ignore[index]
            llm=self.llm_helper.create_llm_instance('researcher'),
            tools=[search_tool],  # Search tool for comprehensive research
            verbose=self.agents_config['researcher'].get('verbose', False)
        )

    @agent
    def writer(self) -> Agent:
        """Tech Thought Leadership Writer agent for blog content creation"""
        return Agent(
            config=self.agents_config['writer'], # type: ignore[index]
            llm=self.llm_helper.create_llm_instance('writer'),
            verbose=self.agents_config['writer'].get('verbose', False)
        )

    @task
    def task_search(self) -> Task:
        """Research task for finding trending skills"""
        return Task(
            config=self.tasks_config['task_search'], # type: ignore[index]
            agent=self.coach()
        )

    @task
    def task_research(self) -> Task:
        """In-depth research task for creating comprehensive content"""
        return Task(
            config=self.tasks_config['task_research'], # type: ignore[index]
            agent=self.researcher(),
            context=[self.task_search()]  # Uses initial skill list as context
        )

    @task
    def task_blog(self) -> Task:
        """Blog creation task for thought leadership content"""
        return Task(
            config=self.tasks_config['task_blog'], # type: ignore[index]
            agent=self.writer(),  # Use the dedicated writer agent
            context=[self.task_research()]  # Uses the in-depth research
        )

    @task
    def task_post(self) -> Task:
        """Content creation task for LinkedIn post"""
        return Task(
            config=self.tasks_config['task_post'], # type: ignore[index]
            agent=self.influencer(),
            context=[self.task_blog()]  # Now correctly uses the blog content
        )

    @crew
    def crew(self) -> Crew:
        """Creates the LinkedIn Content Creation Crew following CrewAI best practices"""
        # Create knowledge sources for the crew using proper file-based sources
        knowledge_sources = []
        
        try:
            # Add web search results knowledge using JSONKnowledgeSource with relative path
            web_knowledge = self.knowledge_helper.get_web_results_knowledge_source()
            knowledge_sources.append(web_knowledge)
            print("üìö Added web search results to crew knowledge")
            
            # Add article memory knowledge using JSONKnowledgeSource with relative path
            article_knowledge = self.knowledge_helper.get_article_memory_knowledge_source()
            knowledge_sources.append(article_knowledge)
            print("üìñ Added article memory to crew knowledge")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Could not load all knowledge sources: {e}")
            print("üîÑ Continuing with crew execution without knowledge sources")
        
        return Crew(
            agents=self.agents,  # Automatically collected by @agent decorator
            tasks=self.tasks,    # Automatically collected by @task decorator
            process=Process.sequential,
            verbose=True,
            max_execution_time=None,
            knowledge_sources=knowledge_sources  # File-based knowledge without embeddings
            # Note: Using StringKnowledgeSource to avoid embedding requirements
            # memory=True,  # Enable memory for better context retention
            # cache=True,   # Enable caching for performance 
            # planning=True,  # Enable planning feature
            # output_log_file="linkedin_crew_logs.json"  # Log execution details
        )
